{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. 5-1 Setup Redshift Serverless with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure a smooth experience with this notebook, please make sure you've set up your Redshift Serverless Namespace and Workgroup beforehand. \n",
    "\n",
    "If you haven't done so already, you can easily set up Redshift Serverless by using the `redshift_serverless.yaml` file for installation. \n",
    "\n",
    "This preparation step is crucial for the proper execution of the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"sqlalchemy<2.0.0\"\n",
    "!pip install -U \"pandas<2.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data from SQLite (Chinook.DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "sqlite_file = '../Chinook.db'\n",
    "sqlite_conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "sqlite_cursor = sqlite_conn.cursor()\n",
    "sqlite_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = sqlite_cursor.fetchall()\n",
    "\n",
    "print(tables)\n",
    "\n",
    "table_name = tables[0][0]\n",
    "data = pd.read_sql_query(f\"SELECT * FROM {table_name}\", sqlite_conn)\n",
    "    \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to Redshift Serverless \n",
    "\n",
    "If you encounter any errors during this process, it may be due to version incompatibilities between `SQLAlchemy` and `pandas`. \n",
    "\n",
    "Let's begin loading our data into Redshift Serverless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "redshift_serverless = boto3.client('redshift-serverless')\n",
    "\n",
    "workgroup_name = 'test-workgroup'\n",
    "response = redshift_serverless.get_workgroup(workgroupName=workgroup_name)\n",
    "endpoint = response['workgroup']['endpoint']\n",
    "print(endpoint['address'])\n",
    "\n",
    "workgroup_arn = response['workgroup']['workgroupArn']\n",
    "print(workgroup_arn)\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "secretsmanager = boto3.client('secretsmanager')\n",
    "\n",
    "redshift_host = endpoint['address']\n",
    "redshift_port = '5439'\n",
    "redshift_dbname = 'testdb'\n",
    "redshift_user = 'admin'\n",
    "redshift_password = 'Admin123!'\n",
    "\n",
    "secret_name = \"redshift-serverless-credentials\"\n",
    "secret_value = {\n",
    "    \"username\": redshift_user,\n",
    "    \"password\": redshift_password\n",
    "}\n",
    "\n",
    "try:\n",
    "    get_secret_value_response = secretsmanager.get_secret_value(SecretId=secret_name)\n",
    "    print(f\"Secret '{secret_name}' already exists. Using existing secret.\")\n",
    "    secret_arn = get_secret_value_response['ARN']\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "        print(f\"Secret '{secret_name}' not found. Creating new secret.\")\n",
    "        try:\n",
    "            secret_response = secretsmanager.create_secret(\n",
    "                Name=secret_name,\n",
    "                SecretString=json.dumps(secret_value)\n",
    "            )\n",
    "            secret_arn = secret_response['ARN']\n",
    "            print(f\"Secret '{secret_name}' created successfully.\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error creating secret: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_data = boto3.client('redshift-data')\n",
    "\n",
    "def grant_select_permission(workgroup_name, database, secrets_username):\n",
    "    query = f'GRANT SELECT ON ALL TABLES IN SCHEMA public TO \"IAMR:{secrets_username}\";'\n",
    "    try:\n",
    "        response = redshift_data.execute_statement(\n",
    "            WorkgroupName=workgroup_name,\n",
    "            Database=database,\n",
    "            Sql=query\n",
    "        )\n",
    "        print(f\"Permission granted. Query execution ID: {response['Id']}\")\n",
    "    except ClientError as e:\n",
    "        print(f\"Error granting permission: {e}\")\n",
    "        raise\n",
    "\n",
    "secrets_username = secret_arn.split(':')[-1]\n",
    "grant_select_permission(\n",
    "    workgroup_name=workgroup_name,\n",
    "    database=redshift_dbname,\n",
    "    secrets_username=secrets_username\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store secret_arn redshift_user workgroup_name workgroup_arn redshift_dbname region account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_conn_string = f\"postgresql://{redshift_user}:{redshift_password}@{redshift_host}:{redshift_port}/{redshift_dbname}\"\n",
    "redshift_engine = create_engine(redshift_conn_string)\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0].lower()    \n",
    "    df = pd.read_sql_query(f\"SELECT * FROM {table[0]}\", sqlite_conn)\n",
    "    print(f\"Processing table: {table_name}\")\n",
    "    df.to_sql(table_name, redshift_engine, index=False, if_exists='replace', method='multi', chunksize=1000)\n",
    "    print(f\"Table {table[0]} created and data inserted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Complex SQL query with Redshift\n",
    "\n",
    "Now that we have our data loaded into Redshift Serverless, let's test a complex SQL query to analyze our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \"What are the top 5 best-selling tracks for each of the 3 highest-grossing genres? Include genre, track, artist, album, and sales\"\n",
    "sample_query = \"\"\"WITH TopGenres AS (\n",
    "    SELECT g.GenreId, g.Name AS GenreName\n",
    "    FROM Genre g\n",
    "    JOIN Track t ON g.GenreId = t.GenreId\n",
    "    JOIN InvoiceLine il ON t.TrackId = il.TrackId\n",
    "    GROUP BY g.GenreId, g.Name\n",
    "    ORDER BY SUM(il.UnitPrice * il.Quantity) DESC\n",
    "    LIMIT 3\n",
    "),\n",
    "RankedTracks AS (\n",
    "    SELECT \n",
    "        g.GenreName,\n",
    "        t.Name AS TrackName,\n",
    "        ar.Name AS ArtistName,\n",
    "        al.Title AS AlbumTitle,\n",
    "        SUM(il.UnitPrice * il.Quantity) AS Sales,\n",
    "        ROW_NUMBER() OVER (PARTITION BY g.GenreId ORDER BY SUM(il.UnitPrice * il.Quantity) DESC) AS Rank\n",
    "    FROM \n",
    "        TopGenres g\n",
    "        JOIN Track t ON g.GenreId = t.GenreId\n",
    "        JOIN Album al ON t.AlbumId = al.AlbumId\n",
    "        JOIN Artist ar ON al.ArtistId = ar.ArtistId\n",
    "        JOIN InvoiceLine il ON t.TrackId = il.TrackId\n",
    "    GROUP BY \n",
    "        g.GenreId, g.GenreName, t.Name, ar.Name, al.Title\n",
    ")\n",
    "SELECT GenreName, TrackName, ArtistName, AlbumTitle, Sales\n",
    "FROM RankedTracks\n",
    "WHERE Rank <= 5\n",
    "ORDER BY GenreName, Sales DESC;\"\"\"\n",
    "\n",
    "with redshift_engine.connect() as conn:\n",
    "    result = conn.execute(text(sample_query))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "    print(df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store sample_query sample_question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
