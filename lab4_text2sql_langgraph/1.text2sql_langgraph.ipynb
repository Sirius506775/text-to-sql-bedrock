{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. 4 LangGraph + Text2SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Intro1](../images/text2sql/langgraph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opensearch-py\n",
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import copy\n",
    "from botocore.config import Config\n",
    "from sqlalchemy import create_engine\n",
    "from src.opensearch import OpenSearchVectorRetriever, OpenSearchClient\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region_name = boto_session.region_name\n",
    "\n",
    "llm_model = \"anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "llm_model = \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "\n",
    "engine = create_engine(\"sqlite:///Chinook.db\")\n",
    "DIALECT = \"sqlite\"\n",
    "\n",
    "def converse_with_bedrock(sys_prompt, usr_prompt):\n",
    "    temperature = 0.0\n",
    "    top_p = 0.1\n",
    "    top_k = 1\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    additional_model_fields = {\"top_k\": top_k}\n",
    "    response = boto3_client.converse(\n",
    "        modelId=llm_model, \n",
    "        messages=usr_prompt, \n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "    return response['output']['message']['content'][0]['text']\n",
    "\n",
    "def init_boto3_client(region: str):\n",
    "    retry_config = Config(\n",
    "        region_name=region,\n",
    "        retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    "    )\n",
    "    return boto3.client(\"bedrock-runtime\", region_name=region, config=retry_config)\n",
    "\n",
    "def init_search_resources():  \n",
    "    \n",
    "    sql_search_client = OpenSearchClient(region_name=region_name, index_name='example_queries', mapping_name='mappings-sql', vector=\"input_v\", text=\"input\", output=[\"input\", \"query\"])\n",
    "    table_search_client = OpenSearchClient(region_name=region_name, index_name='schema_descriptions', mapping_name='mappings-detailed-schema', vector=\"table_summary_v\", text=\"table_summary\", output=[\"table_name\", \"table_summary\"])\n",
    "\n",
    "    sql_retriever = OpenSearchVectorRetriever(sql_search_client, region_name=region_name, k=10)\n",
    "    table_retriever = OpenSearchVectorRetriever(table_search_client, region_name=region_name, k=10)\n",
    "    return sql_search_client, table_search_client, sql_retriever, table_retriever\n",
    "\n",
    "def get_column_description(table_name):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"table_name\": table_name\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = table_search_client.conn.search(index=table_search_client.index_name, body=query)\n",
    "\n",
    "    if response['hits']['total']['value'] > 0:\n",
    "        source = response['hits']['hits'][0]['_source']\n",
    "        columns = source.get('columns', [])\n",
    "        if columns:\n",
    "            return {col['col_name']: col['col_desc'] for col in columns}\n",
    "        else:\n",
    "            return {}\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def search_by_keywords(keyword):\n",
    "    query = {\n",
    "        \"size\": 10, \n",
    "        \"query\": {\n",
    "            \"nested\": {\n",
    "                \"path\": \"columns\",\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        \"columns.col_desc\": f\"{keyword}\"\n",
    "                    }\n",
    "                },\n",
    "                \"inner_hits\": {\n",
    "                    \"size\": 1, \n",
    "                    \"_source\": [\"columns.col_name\", \"columns.col_desc\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"table_name\"]\n",
    "    }\n",
    "    response = table_search_client.conn.search(\n",
    "        index=table_search_client.index_name,\n",
    "        body=query\n",
    "    )\n",
    "    \n",
    "    search_result = \"\"\n",
    "    try:\n",
    "        results = []\n",
    "        table_names = set()  \n",
    "        if 'hits' in response and 'hits' in response['hits']:\n",
    "            for hit in response['hits']['hits']:\n",
    "                table_name = hit['_source']['table_name']\n",
    "                table_names.add(table_name)  \n",
    "                for inner_hit in hit['inner_hits']['columns']['hits']['hits']:\n",
    "                    column_name = inner_hit['_source']['col_name']\n",
    "                    column_description = inner_hit['_source']['col_desc']\n",
    "                    results.append({\n",
    "                        \"table_name\": table_name,\n",
    "                        \"column_name\": column_name,\n",
    "                        \"column_description\": column_description\n",
    "                    })\n",
    "                    if len(results) >= 5:\n",
    "                        break\n",
    "                if len(results) >= 5:\n",
    "                    break\n",
    "        search_result += json.dumps(results, ensure_ascii=False)\n",
    "    except:\n",
    "        search_result += f\"{keyword} not found\"\n",
    "    return search_result    \n",
    "\n",
    "def create_prompt(sys_template, user_template, **kwargs):\n",
    "    sys_prompt = [{\"text\": sys_template.format(**kwargs)}]\n",
    "    usr_prompt = [{\"role\": \"user\", \"content\": [{\"text\": user_template.format(**kwargs)}]}]\n",
    "    return sys_prompt, usr_prompt\n",
    "\n",
    "boto3_client = init_boto3_client(region_name)\n",
    "sql_search_client, table_search_client, sql_retriever, table_retriever = init_search_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Genres people like\"\n",
    "\n",
    "sql_search_result = sql_retriever.vector_search(question)\n",
    "table_search_result = table_retriever.vector_search(question)\n",
    "\n",
    "if sql_search_result:\n",
    "    page_content = json.loads(sql_search_result[0].page_content)\n",
    "    print(\"Sample query search result: \", json.dumps(page_content, indent=4, ensure_ascii=False))\n",
    "\n",
    "if table_search_result:\n",
    "    page_content = json.loads(table_search_result[0].page_content)\n",
    "    print(\"Table search result: \", json.dumps(page_content, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphState Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str  \n",
    "    intent: str\n",
    "    sample_queries: list\n",
    "    readiness: str\n",
    "    tables_summaries: list\n",
    "    table_names: list\n",
    "    table_details: list\n",
    "    query_state: dict\n",
    "    next_action: str\n",
    "    answer: str\n",
    "    dialect: str\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph1 - Schema Linking definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Schema Linking - SubGraph1\n",
    "from sqlalchemy import inspect, text\n",
    "\n",
    "csv_list_response_format = \"Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\"\n",
    "json_response_format = \"\"\"'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'\"\"\"\n",
    "\n",
    "def analyze_intent(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    sys_prompt_template = \"You are an assistant who understands the intent of user questions. Your task is to classify each user question into one category.\"\n",
    "    usr_prompt_template = f\"If a database query is needed to answer the user's question, respond with 'database'. Otherwise, respond with 'general'. Skip any preamble. \\n\\n #Question: {question}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question)\n",
    "    intent = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    return GraphState(intent=intent)\n",
    "\n",
    "def get_sample_queries(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    samples = sql_retriever.vector_search(question)\n",
    "    page_contents = [doc.page_content for doc in samples if doc is not None]\n",
    "    sample_inputs = [json.loads(content)['input'] for content in page_contents]\n",
    "\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries for user questions. Your task is to select sample queries that are useful for creating SQL queries that match the question. The sample queries you select can be used for query reuse, schema reference, etc.\"    \n",
    "    usr_prompt_template = \"Select sample queries that are useful for writing SQL queries that match the question, and respond with them sorted by importance. Respond only with the index numbers of the sample queries (starting from 0). If there are no relevant samples, respond with an empty list (\"\"). \\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_inputs}\\n\\n #Format: {csv_list_response_format}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, sample_inputs=sample_inputs, csv_list_response_format=csv_list_response_format)\n",
    "    sample_ids = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    try:\n",
    "        if sample_ids == '\"\"' or sample_ids.strip() == \"\":\n",
    "            return GraphState(sample_queries=[])\n",
    "        else:\n",
    "            sample_ids_list = [int(id.strip()) for id in sample_ids.split(',') if id.strip().isdigit()]\n",
    "            sample_queries = [json.loads(page_contents[id]) for id in sample_ids_list] if sample_ids_list else []\n",
    "            return GraphState(sample_queries=sample_queries)\n",
    "    except:\n",
    "        return GraphState(sample_queries=[])\n",
    "    \n",
    "def check_readiness(state: GraphState) -> GraphState:\n",
    "    print(state)\n",
    "    question = state[\"question\"]\n",
    "    sample_queries = state[\"sample_queries\"]\n",
    "    table_details = state.get(\"table_details\", \"\")\n",
    "\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries for user questions. Your task is to determine whether it's possible to write an SQL query for the user's question based on the given database information.\"\n",
    "    usr_prompt_template = \"Determine if sufficient information has been provided to generate an SQL query for the question. Respond with 'Ready' if there's enough information, or 'Not Ready' if the information is insufficient. \\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_queries}\\n\\n #Available tables:\\n {table_details} \\n\\n Skip the preamble or explaination. Only provide 'Ready' or 'Not Ready'\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, sample_queries=sample_queries, table_details=table_details)\n",
    "    readiness = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    \n",
    "    return GraphState(readiness=readiness)\n",
    "\n",
    "def get_relevant_tables(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    tables = table_retriever.vector_search(question)\n",
    "    page_contents = [doc.page_content for doc in tables if doc is not None]\n",
    "    table_inputs = [json.loads(content)['table_summary'] for content in page_contents]\n",
    "\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries to match user requests. Your task is to select the tables needed to write the SQL query.\"\n",
    "    usr_prompt_template = \"Select the tables needed to generate an SQL query that matches the user's request, sort them by importance, and respond with their index numbers (starting from 0). If there are no tables relevant to the user's request, respond with an empty list (\"\").\\n\\n #Question: {question}\\n\\n #Table information:\\n {table_inputs}\\n\\n #Format: {csv_list_response_format}\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, table_inputs=table_inputs, csv_list_response_format=csv_list_response_format)\n",
    "    table_ids = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    try:\n",
    "        if table_ids == '\"\"' or table_ids.strip() == \"\":\n",
    "            return GraphState(tables=[], table_names=[])\n",
    "        else:\n",
    "            table_ids_list = [int(id.strip()) for id in table_ids.split(',') if id.strip().isdigit()]\n",
    "            tables = [json.loads(page_contents[id]) for id in table_ids_list] if table_ids_list else []\n",
    "            table_names = [table['table_name'] for table in tables]\n",
    "            return GraphState(tables=tables, table_names=table_names)\n",
    "    except:\n",
    "        return GraphState(tables=[], table_names=[])\n",
    "\n",
    "def describe_schema(state: GraphState) -> GraphState:\n",
    "    table_names = state[\"table_names\"]\n",
    "    table_details = []\n",
    "    inspector = inspect(engine)\n",
    "    \n",
    "    for table_name in table_names:\n",
    "        columns = inspector.get_columns(table_name)\n",
    "\n",
    "        create_table_sql = f\"CREATE TABLE {table_name} (\\n\"\n",
    "        create_table_sql += \",\\n\".join([f\"    {col['name']} {col['type']}\" for col in columns])\n",
    "        create_table_sql += \"\\n);\"\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            sample_query = text(f\"SELECT * FROM {table_name} LIMIT 5\")\n",
    "            result = connection.execute(sample_query)\n",
    "            sample_data = [dict(zip(result.keys(), row)) for row in result]\n",
    "            \n",
    "        table_desc = get_column_description(table_name) if 'table_search_client' in globals() else {}\n",
    "\n",
    "        table_detail = {\n",
    "            \"table\": table_name,\n",
    "            \"cols\": table_desc if table_desc else {col['name']: str(col['type']) for col in columns},\n",
    "            \"create_table_sql\": create_table_sql,\n",
    "            \"sample_data\": str(sample_data) if sample_data else \"No sample data available\"\n",
    "        }\n",
    "\n",
    "        if not table_detail[\"cols\"]:\n",
    "            print(f\"No columns found for table {table_name}\")\n",
    "        table_details.append(table_detail) \n",
    "                    \n",
    "    return GraphState(table_details=table_details)\n",
    "\n",
    "def next_step_by_intent(state: GraphState) -> GraphState:\n",
    "    return state[\"intent\"]\n",
    "\n",
    "def next_step_by_readiness(state: GraphState) -> GraphState:\n",
    "    return state[\"readiness\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph1 - Code modules (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Schema Linking - SubGraph1 Modules (Dev)\n",
    "\n",
    "def analyze_intent_dev(question):\n",
    "    sys_prompt_template = \"You are an assistant who understands the intent of user questions. Your task is to classify each user question into one category.\"\n",
    "    usr_prompt_template = f\"If a database query is needed to answer the user's question, respond with 'database'. Otherwise, respond with 'general'. Skip any preamble. \\n\\n #Question: {question}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question)\n",
    "    intent = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    return intent\n",
    "\n",
    "def get_general_answer_dev(question):\n",
    "    sys_prompt_template = \"You are a capable assistant who answers general questions from users. If you don't know the answer to a question, admit that you don't know.\"\n",
    "    usr_prompt_template = \"#Question: {question}\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question)\n",
    "    answer = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    return answer    \n",
    "\n",
    "def get_sample_queries_dev(question):\n",
    "    samples = sql_retriever.vector_search(question)\n",
    "    page_contents = [doc.page_content for doc in samples if doc is not None]\n",
    "    sample_inputs = [json.loads(content)['input'] for content in page_contents]\n",
    "\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries for user questions. Your task is to select sample queries that are useful for creating SQL queries that match the question. The sample queries you select can be used for query reuse, schema reference, etc.\"    \n",
    "    usr_prompt_template = \"Select sample queries that are useful for writing SQL queries that match the question, and respond with them sorted by importance. Respond only with the index numbers of the sample queries (starting from 0). If there are no relevant samples, respond with an empty list (\"\"). \\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_inputs}\\n\\n #Format: {csv_list_response_format}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, sample_inputs=sample_inputs, csv_list_response_format=csv_list_response_format)\n",
    "    sample_ids = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    try:\n",
    "        if sample_ids == '\"\"' or sample_ids.strip() == \"\":\n",
    "            return []\n",
    "        else:\n",
    "            sample_ids_list = [int(id.strip()) for id in sample_ids.split(',') if id.strip().isdigit()]\n",
    "            sample_queries = [json.loads(page_contents[id]) for id in sample_ids_list] if sample_ids_list else []\n",
    "            return sample_queries\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "def check_readiness_dev(question, sample_queries, table_details):\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries for user questions. Your task is to determine whether it's possible to write an SQL query for the user's question based on the given database information.\"\n",
    "    usr_prompt_template = \"Determine if sufficient information has been provided to generate an SQL query for the question. Skip any preamble and respond with 'Ready' if there's enough information, or 'Not Ready' if the information is insufficient.\\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_queries}\\n\\n #Available tables:\\n {table_details}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, sample_queries=sample_queries, table_details=table_details)\n",
    "    readiness = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    \n",
    "    return readiness\n",
    "\n",
    "def get_relevant_tables_dev(question):\n",
    "    tables = table_retriever.vector_search(question)\n",
    "    page_contents = [doc.page_content for doc in tables if doc is not None]\n",
    "    table_inputs = [json.loads(content)['table_summary'] for content in page_contents]\n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes SQL queries to match user requests. Your task is to select the tables needed to write the SQL query.\"\n",
    "    usr_prompt_template = \"Select the tables needed to generate an SQL query that matches the user's request, sort them by importance, and respond with their index numbers (starting from 0). If there are no tables relevant to the user's request, respond with an empty list (\"\").\\n\\n #Question: {question}\\n\\n #Table information:\\n {table_inputs}\\n\\n #Format: {csv_list_response_format}\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, table_inputs=table_inputs, csv_list_response_format=csv_list_response_format)\n",
    "    table_ids = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    try:\n",
    "        if table_ids == '\"\"' or table_ids.strip() == \"\":\n",
    "            return []\n",
    "        else:\n",
    "            table_ids_list = [int(id.strip()) for id in table_ids.split(',') if id.strip().isdigit()]\n",
    "            tables = [json.loads(page_contents[id]) for id in table_ids_list] if table_ids_list else []\n",
    "            table_names = [table['table_name'] for table in tables]\n",
    "            return tables, table_names\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def describe_schema_dev(table_names):\n",
    "    table_details = []\n",
    "    inspector = inspect(engine)\n",
    "    \n",
    "    for table_name in table_names:\n",
    "        columns = inspector.get_columns(table_name)\n",
    "\n",
    "        create_table_sql = f\"CREATE TABLE {table_name} (\\n\"\n",
    "        create_table_sql += \",\\n\".join([f\"    {col['name']} {col['type']}\" for col in columns])\n",
    "        create_table_sql += \"\\n);\"\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            sample_query = text(f\"SELECT * FROM {table_name} LIMIT 5\")\n",
    "            result = connection.execute(sample_query)\n",
    "            sample_data = [dict(zip(result.keys(), row)) for row in result]\n",
    "            \n",
    "        table_desc = get_column_description(table_name) if 'table_search_client' in globals() else {}\n",
    "\n",
    "        table_detail = {\n",
    "            \"table\": table_name,\n",
    "            \"cols\": table_desc if table_desc else {col['name']: str(col['type']) for col in columns},\n",
    "            \"create_table_sql\": create_table_sql,\n",
    "            \"sample_data\": str(sample_data) if sample_data else \"No sample data available\"\n",
    "        }\n",
    "\n",
    "        if not table_detail[\"cols\"]:\n",
    "            print(f\"No columns found for table {table_name}\")\n",
    "        table_details.append(table_detail)    \n",
    "        \n",
    "    return table_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph1 - Code modules (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Schema Linking - SubGraph1 Modules (Test)\n",
    "\n",
    "question1 = \"What are the top 10 countries by sales in 2022?\"\n",
    "question2 = \"What's the weather like today?\"\n",
    "question3 = \"Who are the top 10 customers based on purchase quantity?\"\n",
    "\n",
    "#===================================================================================================\n",
    "\n",
    "#1 - analyze_intent\n",
    "print(analyze_intent_dev(question1))\n",
    "print(analyze_intent_dev(question2))\n",
    "\n",
    "#2 - get_sample_queries\n",
    "print(get_sample_queries_dev(question1))\n",
    "print(get_sample_queries_dev(question3))\n",
    "\n",
    "#3 - check_readiness\n",
    "sample_queries = [\n",
    "   '{\"input\": \"What are the details of customers residing in Canada?\", \"query\": \"SELECT * FROM Customer WHERE Country = \\'Canada\\'\"}',\n",
    "   '{\"input\": \"How many tracks are on the album with ID 5?\", \"query\": \"SELECT COUNT(*) FROM Track WHERE AlbumId = 5\"}',\n",
    "   '{\"input\": \"What are the top 5 customers by total purchase amount?\", \"query\": \"SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5\"}'\n",
    "]\n",
    "print(check_readiness_dev(question3, sample_queries, table_details=\"\"))\n",
    "\n",
    "#4 - get_relevant_tables\n",
    "print(get_relevant_tables_dev(question1))\n",
    "print(get_relevant_tables_dev(question3))\n",
    "\n",
    "#5 - describe_schema\n",
    "table_names = ['Invoice']\n",
    "print(describe_schema_dev(table_names))\n",
    "\n",
    "#6 - check_readiness\n",
    "table_names = ['Invoice', 'Customer']\n",
    "table_details = describe_schema_dev(table_names)\n",
    "print(check_readiness_dev(question1, sample_queries=\"\", table_details=table_details))\n",
    "\n",
    "# #==================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph2 - Text2SQL Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "### Query Generation & Execution - SubGraph2\n",
    "\n",
    "initial_query_state = {\n",
    "    \"status\": \"success\",\n",
    "    \"query\": \"\",\n",
    "    \"result\": \"\",\n",
    "    \"error\": {\n",
    "        \"code\": \"\",\n",
    "        \"message\": \"\",\n",
    "        \"failed_step\": \"\",\n",
    "        \"hint\": \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_query(state: GraphState) -> GraphState:\n",
    "    dialect = DIALECT\n",
    "    new_query_state = copy.deepcopy(initial_query_state)\n",
    "    question = state[\"question\"]\n",
    "    sample_queries = state[\"sample_queries\"]\n",
    "    table_details = state[\"table_details\"]\n",
    "\n",
    "    query_state = state.get(\"query_state\", {}) or {}\n",
    "    error_info = query_state.get(\"error\", {}) or {}\n",
    "    hint = error_info.get(\"hint\", \"None\")\n",
    "    \n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes {dialect} SQL queries in response to user questions. Your task is to create accurate SQL queries that match the user's question based on the given database information.\"\n",
    "    usr_prompt_template = \"Based on the following sample queries, schema information, and past failure history, create a query that matches the DB dialect. Skip the introduction and provide only the generated SQL query statement. \\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_queries}\\n\\n #Available tables:\\n {table_details}\\n\\n #Additional information (past failure history, additional acquired information, etc.):\\n {hint}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, dialect=dialect, sample_queries=sample_queries, table_details=table_details, hint=hint)\n",
    "    generated_query = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    new_query_state[\"query\"] = generated_query\n",
    "\n",
    "    return GraphState(query_state=new_query_state)\n",
    "\n",
    "def validate_query(state: GraphState) -> GraphState:\n",
    "    dialect = DIALECT\n",
    "    question = state[\"question\"]\n",
    "    query_state = copy.deepcopy(state[\"query_state\"])\n",
    "    query = query_state[\"query\"]\n",
    "    \n",
    "    explain_statements = {\n",
    "        'mysql': \"EXPLAIN {query}\",\n",
    "        'mariadb': \"EXPLAIN {query}\",\n",
    "        'sqlite': \"EXPLAIN QUERY PLAN {query}\",\n",
    "        'oracle': \"EXPLAIN PLAN FOR\\n{query}\\n\\nSELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);\",\n",
    "        'postgresql': \"EXPLAIN ANALYZE {query}\",\n",
    "        'postgres': \"EXPLAIN ANALYZE {query}\",\n",
    "        'presto': \"EXPLAIN ANALYZE {query}\",\n",
    "        'sqlserver': \"SET STATISTICS PROFILE ON; {query}; SET STATISTICS PROFILE OFF;\"\n",
    "    }\n",
    "    \n",
    "    if dialect.lower() not in explain_statements:\n",
    "        query_plan = \" \"\n",
    "    else:\n",
    "        try:\n",
    "            explain_query = explain_statements[dialect.lower()].format(query=query)\n",
    "            with Session() as session:\n",
    "                result = session.execute(text(explain_query))\n",
    "                query_plan = \"\\n\".join([str(row) for row in result])\n",
    "        except Exception as e:\n",
    "            query_state[\"status\"] = \"error\"\n",
    "            query_state[\"error\"][\"code\"] = \"E01\"\n",
    "            query_state[\"error\"][\"message\"] = f\"An error occurred while executing the EXPLAIN query: {str(e)}\"\n",
    "            query_state[\"error\"][\"failed_step\"] = \"validation\"\n",
    "            query_state[\"query\"] = query\n",
    "            return GraphState(query_state=query_state)\n",
    "\n",
    "    sys_prompt_template = \"You are a database expert who reviews existing {dialect} SQL queries in response to user questions and optimizes them when necessary. Your task is to examine the query's coherence and potential for optimization based on the given SQL query and additional information, and provide a final query based on this analysis.\" \n",
    "    usr_prompt_template = \"Please add aliases to the query to match the user's question. It is not allowed to add tables or columns that were not used in the original SQL query. Skip the introduction and provide only the generated SQL query statement. \\n\\n #Question: {question}\\n\\n #Existing query:\\n {query}\\n\\n #Query plan:\\n {query_plan}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, dialect=dialect, query=query, query_plan=query_plan)\n",
    "    validated_query = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    query_state[\"query\"] = validated_query\n",
    "\n",
    "    return GraphState(query_state=query_state)\n",
    "\n",
    "def execute_query(state: GraphState) -> GraphState:\n",
    "    query_state = copy.deepcopy(state[\"query_state\"])\n",
    "    query = query_state[\"query\"]\n",
    "    try:\n",
    "        with Session() as session:\n",
    "            result = session.execute(text(query))\n",
    "            query_state[\"result\"] = \"\\n\".join([str(row) for row in result])\n",
    "    except Exception as e:\n",
    "        query_state[\"status\"] = \"error\"\n",
    "        query_state[\"error\"][\"code\"] = \"E02\"\n",
    "        query_state[\"error\"][\"message\"] = f\"An error occurred while executing the validated query: {str(e)}\"\n",
    "        query_state[\"error\"][\"failed_step\"] = \"execution\"\n",
    "        return GraphState(query_state=query_state)\n",
    "    return GraphState(query_state=query_state)\n",
    "    \n",
    "def handle_failure(state: GraphState) -> GraphState:\n",
    "    query_state = copy.deepcopy(state[\"query_state\"])\n",
    "    query = query_state['query']\n",
    "    message = query_state['error']['message']\n",
    "    sys_prompt_template = \"You are a skilled database engineer who handles SQL query failures. Your task is to identify the cause of failure for the given SQL query and determine the next steps for problem resolution.\"\n",
    "    usr_prompt_template = \"Based on the failure message of the given SQL query, provide one of the following causes (`failure_type`) along with a clue for resolution (`hint`).\\nHere are examples of failure_type choices:\\nInaccurate query syntax: `syntax_check`\\nSchema mismatch: `schema_check`\\nExternal DB factors (permissions, connection issues, etc.): `stop`\\nTemporary DB malfunction (query re-execution needed): `retry`\\n\\n#Failed query: {query}\\n\\n#Failure message: {message}\\n\\n#Format: {json_response_format} Skip the preamble and only provide the valid JSON document.\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, query=query, message=message, json_response_format=json_response_format)\n",
    "    result = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    json_result = json.loads(result)\n",
    "\n",
    "    query_state[\"hint\"] = json_result[\"hint\"]\n",
    "    return GraphState(next_action=json_result[\"failure_type\"], query_state=query_state)\n",
    "\n",
    "def get_relevant_columns(state: GraphState) -> GraphState:\n",
    "    query_state = copy.deepcopy(state[\"query_state\"])\n",
    "    question = state[\"question\"]\n",
    "    query = query_state[\"query\"]\n",
    "    message = query_state['error']['message']\n",
    "    sys_prompt_template = \"You are an expert SQL query troubleshooter. Your task is to analyze failed queries and suggest relevant keywords for schema exploration to resolve the issue.\"\n",
    "    usr_prompt_template = \"\"\"Given a user question, a failed SQL query, and an error message, provide 3-5 relevant keywords or phrases for database schema exploration. These should help in finding the correct table and column names to fix the query.\\n\\n#User question: {question}\\n\\n#Failed query:\\n{query}\\n\\n#Error message:\\n{message}\\n\\nRespond only with a comma-separated list of keywords or short phrases, without any additional text or explanation.\\n\\n#Format: {csv_list_response_format}\"\"\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, message=message, csv_list_response_format=csv_list_response_format)\n",
    "    keywords = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    return keywords\n",
    "\n",
    "def next_step_by_query_state(state:GraphState) -> GraphState:\n",
    "    return state[\"query_state\"][\"status\"]\n",
    "\n",
    "def next_step_by_next_action(state:GraphState) -> GraphState:\n",
    "    return state[\"next_action\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph2 - Code modules (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_dev(question, dialect, sample_queries, table_details, hint):\n",
    "    dialect = dialect\n",
    "    query_state = copy.deepcopy(initial_query_state)\n",
    "    question = question\n",
    "    sample_queries = sample_queries\n",
    "    table_details = table_details\n",
    "    hint = hint\n",
    "    \n",
    "    sys_prompt_template = \"You are a skilled database engineer who writes {dialect} SQL queries in response to user questions. Your task is to create accurate SQL queries that match the user's question based on the given database information.\"\n",
    "    usr_prompt_template = \"Based on the following sample queries, schema information, and past failure history, create a query that matches the DB dialect. Skip the introduction and provide only the generated SQL query statement. \\n\\n #Question: {question}\\n\\n #Sample queries:\\n {sample_queries}\\n\\n #Available tables:\\n {table_details}\\n\\n #Additional information (past failure history, additional acquired information, etc.):\\n {hint}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, dialect=dialect, sample_queries=sample_queries, table_details=table_details, hint=hint)\n",
    "    generated_query = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    query_state[\"query\"] = generated_query\n",
    "    return copy.deepcopy(query_state)\n",
    "\n",
    "def validate_query_dev(question, dialect, query_state):\n",
    "    question = question\n",
    "    query_state = copy.deepcopy(query_state)\n",
    "    query = query_state[\"query\"]\n",
    "    \n",
    "    explain_statements = {\n",
    "        'mysql': \"EXPLAIN {query}\",\n",
    "        'mariadb': \"EXPLAIN {query}\",\n",
    "        'sqlite': \"EXPLAIN QUERY PLAN {query}\",\n",
    "        'oracle': \"EXPLAIN PLAN FOR\\n{query}\\n\\nSELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);\",\n",
    "        'postgresql': \"EXPLAIN ANALYZE {query}\",\n",
    "        'postgres': \"EXPLAIN ANALYZE {query}\",\n",
    "        'presto': \"EXPLAIN ANALYZE {query}\",\n",
    "        'sqlserver': \"SET STATISTICS PROFILE ON; {query}; SET STATISTICS PROFILE OFF;\"\n",
    "    }\n",
    "    \n",
    "    if dialect.lower() not in explain_statements:\n",
    "        query_plan = \" \"\n",
    "    else:\n",
    "        try:\n",
    "            explain_query = explain_statements[dialect.lower()].format(query=query)\n",
    "            query_plan = db.run(explain_query)\n",
    "        except Exception as e:\n",
    "            query_state[\"status\"] = \"error\"\n",
    "            query_state[\"error\"][\"code\"] = \"E01\"\n",
    "            query_state[\"error\"][\"message\"] = f\"An error occurred while executing the EXPLAIN query: {str(e)}\"\n",
    "            query_state[\"error\"][\"failed_step\"] = \"validation\"\n",
    "            query_state[\"query\"] = query\n",
    "            return copy.deepcopy(query_state)\n",
    "\n",
    "    sys_prompt_template = \"You are a database expert who reviews existing {dialect} SQL queries in response to user questions and optimizes them when necessary. Your task is to examine the query's coherence and potential for optimization based on the given SQL query and additional information, and provide a final query based on this analysis.\" \n",
    "    usr_prompt_template = \"Please add aliases to the query to match the user's question. It is not allowed to add tables or columns that were not used in the original SQL query. Skip the introduction and provide only the generated SQL query statement. \\n\\n #Question: {question}\\n\\n #Existing query:\\n {query}\\n\\n #Query plan:\\n {query_plan}\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, dialect=dialect, query=query, query_plan=query_plan)\n",
    "    validated_query = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    query_state[\"query\"] = validated_query\n",
    "\n",
    "    return copy.deepcopy(query_state)\n",
    "\n",
    "def execute_query_dev(query_state):\n",
    "    query = query_state[\"query\"]\n",
    "    try:\n",
    "        query_state[\"result\"] = db.run(query)\n",
    "    except Exception as e:\n",
    "        query_state[\"status\"] = \"error\"\n",
    "        query_state[\"error\"][\"code\"] = \"E02\"\n",
    "        query_state[\"error\"][\"message\"] = f\"An error occurred while executing the validated query: {str(e)}\"\n",
    "        query_state[\"error\"][\"failed_step\"] = \"execution\"\n",
    "        return copy.deepcopy(query_state)\n",
    "    return copy.deepcopy(query_state)\n",
    "    \n",
    "def handle_failure_dev(query_state):\n",
    "    query = query_state['query']\n",
    "    message = query_state['error']['message']\n",
    "    sys_prompt_template = \"You are a skilled database engineer who handles SQL query failures. Your task is to identify the cause of failure for the given SQL query and determine the next steps for problem resolution.\"\n",
    "    usr_prompt_template = \"Based on the failure message of the given SQL query, provide one of the following causes (`failure_type`) along with a clue for resolution (`hint`).\\nHere are examples of failure_type choices:\\nInaccurate query syntax: `syntax_check`\\nSchema mismatch: `schema_check`\\nExternal DB factors (permissions, connection issues, etc.): `stop`\\nTemporary DB malfunction (query re-execution needed): `retry`\\n\\n#Failed query: {query}\\n\\n#Failure message: {message}\\n\\n#Format: {json_response_format} Skip the preamble and only provide the valid JSON document.\"    \n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, query=query, message=message, json_response_format=json_response_format)\n",
    "    result = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    json_result = json.loads(result)\n",
    "\n",
    "    query_state[\"hint\"] = json_result.get(\"hint\", \"None\")\n",
    "    failure_type = json_result.get(\"failure_type\", \"Invalid Response\")\n",
    "    return failure_type, copy.deepcopy(query_state)\n",
    "\n",
    "def get_relevant_columns_dev(question, query_state):\n",
    "    query_state = copy.deepcopy(query_state)\n",
    "    question = question\n",
    "    query = query_state[\"query\"]\n",
    "    message = query_state['error']['message']\n",
    "    sys_prompt_template = \"You are an expert SQL query troubleshooter. Your task is to analyze failed queries and suggest relevant keywords for schema exploration to resolve the issue.\"\n",
    "    usr_prompt_template = \"\"\"Given a user question, a failed SQL query, and an error message, provide 3-5 relevant keywords or phrases for database schema exploration. These should help in finding the correct table and column names to fix the query.\\n\\n#User question: {question}\\n\\n#Failed query:\\n{query}\\n\\n#Error message:\\n{message}\\n\\nRespond only with a comma-separated list of keywords or short phrases, without any additional text or explanation.\\n\\n#Format: {csv_list_response_format}\"\"\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, message=message, csv_list_response_format=csv_list_response_format)\n",
    "    response = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    \n",
    "    keyword_list = [keyword.strip() for keyword in response.strip('`').split(',')]\n",
    "    print(\"search keyword:\", keyword_list)\n",
    "    query_state[\"hint\"] += \"\\n\\n#Additional Schema:\\n\"\n",
    "    for keyword in keyword_list:\n",
    "        query_state[\"hint\"] += search_by_keywords(keyword)\n",
    "        query_state[\"hint\"] += \"\\n\"\n",
    "\n",
    "    return copy.deepcopy(query_state)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubGraph2 - Code modules (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================================\n",
    "\n",
    "#7 - generate_query\n",
    "dialect = \"sqlite\"\n",
    "question = \"What are the top 10 countries by sales in 2022?\"\n",
    "sample_queries =  [{'input': 'What are the top 5 customers by total purchase amount?',\n",
    "  'query': 'SELECT CustomerId, SUM(Total) AS TotalPurchase FROM Invoice GROUP BY CustomerId ORDER BY TotalPurchase DESC LIMIT 5'}]\n",
    "table_details = [{'table': 'Customer',\n",
    "  'cols': {'CustomerId': 'Primary key, unique customer identifier.',\n",
    "   'FirstName': 'First name of the customer.',\n",
    "   'LastName': 'Last name of the customer.',\n",
    "   'Company': 'Company of the customer.',\n",
    "   'Address': 'Address of the customer.',\n",
    "   'City': 'City of the customer.',\n",
    "   'State': 'State of the customer.',\n",
    "   'Country': 'Country of the customer.',\n",
    "   'PostalCode': 'Postal code of the customer.',\n",
    "   'Phone': 'Phone number of the customer.',\n",
    "   'Fax': 'Fax number of the customer.',\n",
    "   'Email': 'Email address of the customer.',\n",
    "   'SupportRepId': 'Foreign key that references the employee who supports this customer.'},\n",
    "  'create_table_sql': 'CREATE TABLE \"Customer\" (\\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"FirstName\" NVARCHAR(40) NOT NULL, \\n\\t\"LastName\" NVARCHAR(20) NOT NULL, \\n\\t\"Company\" NVARCHAR(80), \\n\\t\"Address\" NVARCHAR(70), \\n\\t\"City\" NVARCHAR(40), \\n\\t\"State\" NVARCHAR(40), \\n\\t\"Country\" NVARCHAR(40), \\n\\t\"PostalCode\" NVARCHAR(10), \\n\\t\"Phone\" NVARCHAR(24), \\n\\t\"Fax\" NVARCHAR(24), \\n\\t\"Email\" NVARCHAR(60) NOT NULL, \\n\\t\"SupportRepId\" INTEGER, \\n\\tPRIMARY KEY (\"CustomerId\"), \\n\\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\\n)',\n",
    "  'sample_data': '3 rows from Customer table:\\nCustomerId\\tFirstName\\tLastName\\tCompany\\tAddress\\tCity\\tState\\tCountry\\tPostalCode\\tPhone\\tFax\\tEmail\\tSupportRepId\\n1\\tLuís\\tGonçalves\\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\\tAv. Brigadeiro Faria Lima, 2170\\tSão José dos Campos\\tSP\\tBrazil\\t12227-000\\t+55 (12) 3923-5555\\t+55 (12) 3923-5566\\tluisg@embraer.com.br\\t3\\n2\\tLeonie\\tKöhler\\tNone\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t+49 0711 2842222\\tNone\\tleonekohler@surfeu.de\\t5\\n3\\tFrançois\\tTremblay\\tNone\\t1498 rue Bélanger\\tMontréal\\tQC\\tCanada\\tH2G 1A7\\t+1 (514) 721-4711\\tNone\\tftremblay@gmail.com\\t3'},\n",
    " {'table': 'Invoice',\n",
    "  'cols': {'InvoiceId': 'Primary key, unique identifier for the invoice.',\n",
    "   'CustomerId': 'Foreign key that references the customer associated with this invoice.',\n",
    "   'InvoiceDate': 'Date when the invoice was issued.',\n",
    "   'BillingAddress': 'Billing address on the invoice.',\n",
    "   'BillingCity': 'Billing city on the invoice.',\n",
    "   'BillingState': 'Billing state on the invoice.',\n",
    "   'BillingCountry': 'Billing country on the invoice.',\n",
    "   'BillingPostalCode': 'Billing postal code on the invoice.',\n",
    "   'Total': 'Total amount of the invoice.'},\n",
    "  'create_table_sql': 'CREATE TABLE \"Invoice\" (\\n\\t\"InvoiceId\" INTEGER NOT NULL, \\n\\t\"CustomerId\" INTEGER NOT NULL, \\n\\t\"InvoiceDate\" DATETIME NOT NULL, \\n\\t\"BillingAddress\" NVARCHAR(70), \\n\\t\"BillingCity\" NVARCHAR(40), \\n\\t\"BillingState\" NVARCHAR(40), \\n\\t\"BillingCountry\" NVARCHAR(40), \\n\\t\"BillingPostalCode\" NVARCHAR(10), \\n\\t\"Total\" NUMERIC(10, 2) NOT NULL, \\n\\tPRIMARY KEY (\"InvoiceId\"), \\n\\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\\n)',\n",
    "  'sample_data': '3 rows from Invoice table:\\nInvoiceId\\tCustomerId\\tInvoiceDate\\tBillingAddress\\tBillingCity\\tBillingState\\tBillingCountry\\tBillingPostalCode\\tTotal\\n1\\t2\\t2021-01-01 00:00:00\\tTheodor-Heuss-Straße 34\\tStuttgart\\tNone\\tGermany\\t70174\\t1.98\\n2\\t4\\t2021-01-02 00:00:00\\tUllevålsveien 14\\tOslo\\tNone\\tNorway\\t0171\\t3.96\\n3\\t8\\t2021-01-03 00:00:00\\tGrétrystraat 63\\tBrussels\\tNone\\tBelgium\\t1000\\t5.94'}]\n",
    "\n",
    "print(generate_query_dev(question=question, dialect=dialect, sample_queries=sample_queries, table_details=table_details, hint=\"None\"))\n",
    "\n",
    "#8 - validate_query\n",
    "question = \"What are the top 10 countries by sales in 2022?\"\n",
    "query_state = {'status': 'success',\n",
    " 'query': \"SELECT BillingCountry, SUM(Total) AS TotalSales\\nFROM Invoice\\nWHERE InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY BillingCountry\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    " 'result': '',\n",
    " 'error': {'code': '', 'message': '', 'failed_step': '', 'hint': 'None'}}\n",
    "\n",
    "print(validate_query_dev(question, dialect, query_state))\n",
    "\n",
    "#9 - execute_query\n",
    "query_state = {'status': 'success',\n",
    " 'query': \"SELECT BillingCountry AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    " 'result': '',\n",
    " 'error': {'code': '', 'message': '', 'failed_step': '', 'hint': 'None'}}\n",
    "\n",
    "print(execute_query_dev(query_state))\n",
    "\n",
    "#10 - handle_failure\n",
    "query_state_type1 = {'status': 'error',\n",
    " 'query': \"SELECT Billing AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    " 'result': '',\n",
    " 'error': {'code': 'E02',\n",
    "  'message': \"An error occurred while executing the validated query: (sqlite3.OperationalError) no such column: Billing\\n[SQL: SELECT Billing AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\",\n",
    "  'failed_step': 'execution',\n",
    "  'hint': \"None\"}}\n",
    "handle_failure_dev(query_state_type1)\n",
    "\n",
    "query_state_type2 = {'status': 'error',\n",
    " 'query': \"SELECTS BillingCountry AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    " 'result': '',\n",
    " 'error': {'code': 'E02',\n",
    "  'message': 'An error occurred while executing the validated query: (sqlite3.OperationalError) near \"SELECTS\": syntax error\\n[SQL: SELECTS BillingCountry AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN \\'2022-01-01\\' AND \\'2022-12-31\\'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)',\n",
    "  'failed_step': 'execution',\n",
    "  'hint': 'None'}}\n",
    "handle_failure_dev(query_state_type2)\n",
    "\n",
    "# #11 - get_relevant_column\n",
    "question = \"What are the top 10 countries by sales in 2022?\"\n",
    "query_state = {'status': 'error',\n",
    "  'query': \"SELECT Country AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    "  'result': '',\n",
    "  'error': {'code': 'E02',\n",
    "   'message': \"An error occurred while executing the validated query: (sqlite3.OperationalError) no such column: Country\\n[SQL: SELECT Billing AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;]\\n(Background on this error at: https://sqlalche.me/e/20/e3q8)\",\n",
    "   'failed_step': 'execution',\n",
    "   'hint': 'None'},\n",
    "  'hint': \"The column name 'Country' does not exist in the Invoice table.\"}\n",
    "\n",
    "get_relevant_columns_dev(question, query_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer generation nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_answer(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    sys_prompt_template = \"You are a capable assistant who answers general questions from users. If you don't know the answer to a question, admit that you don't know.\"\n",
    "    usr_prompt_template = \"#Question: {question}\"\n",
    "    sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question)\n",
    "    answer = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "\n",
    "    return GraphState(answer=answer)\n",
    "\n",
    "def get_database_answer(state: GraphState) -> GraphState:\n",
    "    question = state[\"question\"]\n",
    "    query_state = state[\"query_state\"]\n",
    "    query = query_state[\"query\"]\n",
    "    data = query_state[\"result\"]\n",
    "    failed_step = query_state[\"error\"][\"failed_step\"]\n",
    "    message = query_state[\"error\"][\"message\"]\n",
    "    sys_prompt_template = \"You are a competent assistant who answers user questions based on database information. Your task is to provide thorough answers to user questions, referencing the given information.\"\n",
    "    \n",
    "    if query_state[\"status\"] == \"success\":\n",
    "        usr_prompt_template = \"The answer should include the used query, dataframe (as a Markdown Table), and a brief response to the question. \\n\\n#Question: {question}\\n\\n#Used query: {query}\\n\\n#Data: {data}\\n\\n\"\n",
    "        sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, data=data)\n",
    "    else:\n",
    "        usr_prompt_template = \"The following is a record of a failed query execution for a user question. Based on this, explain why the request processing failed.\\n\\n#Question: {question}\\n\\n#Used query: {query}\\n\\n#Failed step: {failed_step}\\n\\n#Error message: {message}\\n\\n\"\n",
    "        sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, failed_step=failed_step, message=message)    \n",
    "        \n",
    "    answer = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    return GraphState(answer=answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer generation - Code modules (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_answer_dev(question, query_state) -> GraphState:\n",
    "    question = question\n",
    "    query_state = query_state\n",
    "    query = query_state[\"query\"]\n",
    "    data = query_state[\"result\"]\n",
    "    failed_step = query_state[\"error\"][\"failed_step\"]\n",
    "    message = query_state[\"error\"][\"message\"]\n",
    "    sys_prompt_template = \"You are a competent assistant who answers user questions based on database information. Your task is to provide thorough answers to user questions, referencing the given information.\"\n",
    "    \n",
    "    if query_state[\"status\"] == \"success\":\n",
    "        usr_prompt_template = \"The answer should include the used query, dataframe (as a Markdown Table), and a brief response to the question. \\n\\n#Question: {question}\\n\\n#Used query: {query}\\n\\n#Data: {data}\\n\\n\"\n",
    "        sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, data=data)\n",
    "    else:\n",
    "        usr_prompt_template = \"The following is a record of a failed query execution for a user question. Based on this, explain why the request processing failed.\\n\\n#Question: {question}\\n\\n#Used query: {query}\\n\\n#Failed step: {failed_step}\\n\\n#Error message: {message}\\n\\n\"\n",
    "        sys_prompt, usr_prompt = create_prompt(sys_prompt_template, usr_prompt_template, question=question, query=query, failed_step=failed_step, message=message)    \n",
    "        \n",
    "    answer = converse_with_bedrock(sys_prompt, usr_prompt)\n",
    "    return GraphState(answer=answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 답변 생성 - 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the top 10 countries by sales in 2022?\"\n",
    "query_state = {'status': 'success',\n",
    " 'query': \"SELECT BillingCountry AS Country, SUM(Total) AS TotalSales\\nFROM Invoice i\\nWHERE i.InvoiceDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY Country\\nORDER BY TotalSales DESC\\nLIMIT 10;\",\n",
    " 'result': \"[('USA', 102.98), ('Canada', 76.26), ('Brazil', 41.6), ('France', 39.6), ('Hungary', 32.75), ('United Kingdom', 30.689999999999998), ('Austria', 27.77), ('Germany', 25.74), ('Chile', 17.91), ('India', 17.83)]\",\n",
    " 'error': {'code': '', 'message': '', 'failed_step': '', 'hint': 'None'}}\n",
    "\n",
    "answer = get_database_answer_dev(question, query_state)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph 워크플로 그래프 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Global Nodes\n",
    "workflow.add_node(\"analyze_intent\", analyze_intent)\n",
    "workflow.add_node(\"get_general_answer\", get_general_answer)\n",
    "workflow.add_node(\"get_database_answer\", get_database_answer)\n",
    "workflow.set_entry_point(\"analyze_intent\")\n",
    "\n",
    "# SubGraph1 Nodes - Schema Linking\n",
    "workflow.add_node(\"get_sample_queries\", get_sample_queries)\n",
    "workflow.add_node(\"check_readiness\", check_readiness)\n",
    "workflow.add_node(\"get_relevant_tables\", get_relevant_tables)\n",
    "workflow.add_node(\"describe_schema\", describe_schema)\n",
    "\n",
    "# SubGraph2 Nodes - Query Generation & Execution\n",
    "workflow.add_node(\"generate_query\", generate_query)\n",
    "workflow.add_node(\"validate_query\", validate_query)\n",
    "workflow.add_node(\"execute_query\", execute_query)\n",
    "workflow.add_node(\"handle_failure\", handle_failure)\n",
    "workflow.add_node(\"get_relevant_columns\", get_relevant_columns)\n",
    "\n",
    "# Edge from Entry to SubGraph1\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_intent\",\n",
    "    next_step_by_intent,\n",
    "    {\n",
    "        \"database\": \"get_sample_queries\",\n",
    "        \"general\": \"get_general_answer\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Edges in SubGraph1\n",
    "workflow.add_edge(\"get_sample_queries\", \"check_readiness\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_readiness\"    ,\n",
    "    next_step_by_readiness,\n",
    "    {\n",
    "        \"Ready\": \"generate_query\",\n",
    "        \"Not Ready\": \"get_relevant_tables\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"get_relevant_tables\", \"describe_schema\")\n",
    "workflow.add_edge(\"describe_schema\", \"check_readiness\")\n",
    "\n",
    "# Edges in SubGraph2\n",
    "workflow.add_edge(\"generate_query\", \"validate_query\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate_query\"    ,\n",
    "    next_step_by_query_state,\n",
    "    {\n",
    "        \"success\": \"execute_query\",\n",
    "        \"error\": \"handle_failure\"\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"execute_query\"    ,\n",
    "    next_step_by_query_state,\n",
    "    {\n",
    "        \"success\": \"get_database_answer\",\n",
    "        \"error\": \"handle_failure\"\n",
    "    }\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_failure\"    ,\n",
    "    next_step_by_next_action,\n",
    "    {\n",
    "        \"schema_check\": \"get_relevant_columns\",\n",
    "        \"syntax_check\": \"generate_query\",\n",
    "        \"retry\": \"validate_query\",\n",
    "        \"stop\": \"get_database_answer\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"get_relevant_columns\", \"generate_query\")\n",
    "\n",
    "# Edges to END\n",
    "workflow.add_edge(\"get_general_answer\", END)\n",
    "workflow.add_edge(\"get_database_answer\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Workflow - Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    "    )  \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Workflow End-to-End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"TODO\"})\n",
    "inputs = GraphState(question=\"What are the top 10 countries by sales in 2022?\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=200, compact=True)\n",
    "\n",
    "try:\n",
    "    for output in app.stream(inputs, config=config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"\\n🔹 [NODE] {key}\")\n",
    "            print(\"=\" * 80)\n",
    "            for k, v in value.items():\n",
    "                print(f\"📌 {k}:\")\n",
    "                pp.pprint(v)\n",
    "            print(\"=\" * 80)\n",
    "except GraphRecursionError as e:\n",
    "    print(f\"⚠️ Recursion limit reached: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from langgraph.errors import GraphRecursionError\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"TODO\"})\n",
    "inputs = GraphState(question=\"What is AWS?\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=200, compact=True)\n",
    "\n",
    "try:\n",
    "    for output in app.stream(inputs, config=config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"\\n🔹 [NODE] {key}\")\n",
    "            print(\"=\" * 80)\n",
    "            for k, v in value.items():\n",
    "                print(f\"📌 {k}:\")\n",
    "                pp.pprint(v)\n",
    "            print(\"=\" * 80)\n",
    "except GraphRecursionError as e:\n",
    "    print(f\"⚠️ Recursion limit reached: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
