{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde141b9-c4c6-44b0-b939-2a8dca3b27fb",
   "metadata": {},
   "source": [
    "# Lab. 2-3 Detailed Schema Preparation (for Multi-table Text2SQL)\n",
    "\n",
    "In this notebook, we'll be focusing on the '3. Table Summarizer' process as illustrated in the diagram below.\n",
    "\n",
    "Typically, the Schema Linking process for multi-table structure is divided into two steps: table selection followed by column selection. It's crucial to have comprehensive descriptions for each table because if the wrong table is selected, all subsequent steps become meaningless.\n",
    "\n",
    "This notebook will simulate the process of using a LLM to create detailed descriptive documents for each table.\n",
    "\n",
    "![Intro](../images/text2sql/schema-prep-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d4222-ceff-47ea-b491-8adac0f315d8",
   "metadata": {},
   "source": [
    "## Step 0: OpenSearch Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2651af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c70963-24c8-4a71-8529-37ed362b5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region_name = boto_session.region_name\n",
    "\n",
    "print(f\"OpenSearch Serverless Endpoint: {collection_endpoint}\")\n",
    "print(f\"Dashboard Endpoint: {dashboard_endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed1666-159c-42f4-9664-84161e1fdbd9",
   "metadata": {},
   "source": [
    "## Step 1: Loading `Schema Description` & `Example Queries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6749a59-1105-49ce-9601-1bdb91d7fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "SCHEMA_FILE_PATH = \"../db_metadata/chinook_schema.json\"\n",
    "SAMPLE_QUERY_FILE_PATH = \"../db_metadata/example_queries_temp.jsonl\"\n",
    "\n",
    "def load_schema(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        schema = json.load(file)\n",
    "    return schema\n",
    "\n",
    "def load_queries(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        queries = file.readlines()\n",
    "    return queries\n",
    "\n",
    "schema = load_schema(SCHEMA_FILE_PATH)\n",
    "queries = load_queries(SAMPLE_QUERY_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a650d-2612-440c-835a-ebd1dbab66a4",
   "metadata": {},
   "source": [
    "## Step 2: Table summrization\n",
    "\n",
    "We utilize various information to generate table summary documents.\n",
    "\n",
    "We create table summaries using all available resources, including the basic Schema Description document and Sample Queries.\n",
    "\n",
    "Below is an LLM prompt template designed to incorporate this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867584b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "llm_model = \"anthropic.claude-3-5-haiku-20241022-v1:0\"\n",
    "\n",
    "def init_boto3_client(region: str):\n",
    "    retry_config = Config(\n",
    "        region_name=region,\n",
    "        retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    "    )\n",
    "    return boto3.client(\"bedrock-runtime\", region_name=region, config=retry_config)\n",
    "\n",
    "def converse_with_bedrock(boto3_client, sys_prompt, usr_prompt):    \n",
    "    temperature = 0.0\n",
    "    top_p = 0.1\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "    \n",
    "    response = boto3_client.converse(\n",
    "        modelId=llm_model, \n",
    "        messages=usr_prompt, \n",
    "        system=sys_prompt,\n",
    "        inferenceConfig=inference_config\n",
    "    )\n",
    "\n",
    "    return response['output']['message']['content'][0]['text']\n",
    "\n",
    "def search_table_queries(queries, table_name): \n",
    "    table_name_lower = table_name.lower()\n",
    "    matched_queries = []\n",
    "\n",
    "    for line in queries:\n",
    "        try:\n",
    "            query_data = json.loads(line)\n",
    "            if table_name_lower in query_data['query'].lower():\n",
    "                matched_queries.append(query_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON line: {line}\")\n",
    "    \n",
    "    return matched_queries\n",
    "\n",
    "boto3_client = init_boto3_client(region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd9b880-aba2-4708-8f83-1287771a3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_sys_prompt = [{\n",
    "    \"text\": \"\"\"\n",
    "You are an SQL expert. Provide a concise summary of a specific database table in 200 characters or less. Include:\n",
    "\n",
    "1. Table's primary function\n",
    "2. Key relationships (primary/foreign keys)\n",
    "3. Unique role in the database context\n",
    "4. How it connects to other tables\n",
    "\n",
    "Focus on essential, non-redundant information that captures the table's core purpose and significance in the schema.\n",
    "\"\"\"\n",
    "}]\n",
    "\n",
    "\n",
    "def get_summarization_prompt(all_tables_schema, target_table_schema, sample_queries):\n",
    "    return [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": f\"\"\"\n",
    "<all_tables>\n",
    "{all_tables_schema}\n",
    "</all_tables>\n",
    "\n",
    "<target_table>\n",
    "{target_table_schema}\n",
    "</target_table>\n",
    "\n",
    "<sample_queries>\n",
    "{sample_queries}\n",
    "</sample_queries>\n",
    "\n",
    "Based on the provided information about all tables in the database, the specific schema of the target table, and the sample queries, provide a concise summary and context for the target table. \n",
    "Follow the structure specified in your instructions, focusing on the table's role in the overall database and its unique characteristics.\n",
    "\"\"\"}]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583e3f3-f34a-4854-a580-27644c92f25e",
   "metadata": {},
   "source": [
    "#### Based on the given information, we will extract a summary document for the table named `Customer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719069d-dc8c-4de1-b289-746c83fb619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'Customer'\n",
    "\n",
    "matched_queries = search_table_queries(queries, table_name)\n",
    "\n",
    "for query in matched_queries:\n",
    "    print(query[\"query\"], \"\\n\")\n",
    "    print(query[\"input\"])\n",
    "    print(\"\\n--------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33296a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarization_sys_prompt[0][\"text\"])\n",
    "\n",
    "all_tables_schema = json.dumps(schema, indent=2)\n",
    "target_table_schema = json.dumps(schema[0][table_name], indent=2)\n",
    "\n",
    "summarization_user_prompt = get_summarization_prompt(all_tables_schema, target_table_schema, matched_queries)\n",
    "\n",
    "print(summarization_user_prompt[0][\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3208f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summary = converse_with_bedrock(boto3_client, summarization_sys_prompt, summarization_user_prompt)\n",
    "\n",
    "print(table_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f811120-5c0d-4478-81f1-f66469dbb093",
   "metadata": {},
   "source": [
    "#### The code below performs this operation for all tables in the Schema Description (it takes about 2-3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72ab1fd-3a57-4aca-9070-e7f0530e5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_FILE_PATH1 = \"../db_metadata/chinook_detailed_schema_temp.json\"\n",
    "\n",
    "def summarize_table(table_name, table_desc, all_tables_schema, summarization_sys_prompt, queries):\n",
    "    table_summary = converse_with_bedrock(boto3_client, \n",
    "                                          summarization_sys_prompt, \n",
    "                                          get_summarization_prompt(all_tables_schema, table_desc, queries))\n",
    "    table_desc['table_summary'] = table_summary \n",
    "    return {table_name: table_desc}\n",
    "\n",
    "\n",
    "def write_summaries_to_file(summaries, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as output_file:\n",
    "        json.dump(summaries, output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def process_schema(schema, summarization_sys_prompt, queries):\n",
    "    summaries = []\n",
    "    all_tables_schema = json.dumps(schema, indent=2)\n",
    "    for table_info in schema:\n",
    "        for table_name, table_desc in table_info.items():\n",
    "            matched_queries = search_table_queries(queries, table_name)\n",
    "            summary = summarize_table(table_name, table_desc, all_tables_schema, summarization_sys_prompt, matched_queries)\n",
    "            summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "table_summaries = process_schema(schema, summarization_sys_prompt, queries)\n",
    "write_summaries_to_file(table_summaries, OUTPUT_FILE_PATH1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556af33c-7a19-4df4-b3fa-d7fa38836eb7",
   "metadata": {},
   "source": [
    "In the `chinook_detailed_schema_temp.json` file, the `table_summary` has been added to the schema document.\n",
    "\n",
    "As demonstrated above, providing the LLM with detailed information about 1) what columns are in the table, and 2) how the table is used, helps in selecting the correct table.\n",
    "\n",
    "However, when the table summaries become too long, it's not feasible to pass summaries of all tables to the LLM. In such cases, it's better to explore the table summary information using vector similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56a62d-12da-4548-ac46-49c322dbbd99",
   "metadata": {},
   "source": [
    "## Step 3: Transform documents to vector embeddings and Store in OpenSearch\n",
    "\n",
    "This step proceeds similarly to the sample query storage process performed in `2.sample_queries.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fbb15a-f521-482e-b5df-6a8cd8d4ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import yaml\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region_name = boto_session.region_name\n",
    "INDEX_NAME = \"schema_descriptions\"\n",
    "\n",
    "def load_opensearch_config():\n",
    "    with open(\"./libs/opensearch.yml\", 'r', encoding='utf-8') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def init_opensearch(config):\n",
    "    mapping = {\"settings\": config['settings'], \"mappings\": config['mappings-detailed-schema']}\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    auth = AWSV4SignerAuth(credentials, region_name, 'aoss')\n",
    "    \n",
    "    host = collection_endpoint.replace(\"https://\", \"\").split(':')[0]\n",
    "    \n",
    "    client = OpenSearch(\n",
    "        hosts=[{'host': host, 'port': 443}],\n",
    "        http_auth=auth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        pool_maxsize=20\n",
    "    )\n",
    "    create_os_index(client, mapping)\n",
    "    return client\n",
    "\n",
    "def create_os_index(client, mapping):\n",
    "    exists = client.indices.exists(INDEX_NAME)\n",
    "    if exists:\n",
    "        client.indices.delete(index=INDEX_NAME)\n",
    "        print(\"Existing index has been deleted. Create new one.\")\n",
    "    else:\n",
    "        print(\"Index does not exist, Create one.\")\n",
    "\n",
    "    client.indices.create(INDEX_NAME, body=mapping)\n",
    "\n",
    "\n",
    "config = load_opensearch_config()\n",
    "os_client = init_opensearch(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "827bcc97-974a-4fa2-b643-ca6f7519e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "OUTPUT_FILE_PATH2 = \"../db_metadata/chinook_detailed_schema.json\"\n",
    "\n",
    "def summary_embedding():\n",
    "    with open(OUTPUT_FILE_PATH1, 'r', encoding='utf-8') as input_file:\n",
    "        data_list = json.load(input_file)\n",
    "\n",
    "    for data in data_list:\n",
    "        table_name = list(data.keys())[0]\n",
    "        table_summary = data[table_name][\"table_summary\"]\n",
    "\n",
    "        response = boto3_client.invoke_model(\n",
    "                modelId=embed_model,\n",
    "                body=json.dumps({\"inputText\": table_summary})\n",
    "            )\n",
    "        \n",
    "        data[table_name][\"table_summary_v\"] = json.loads(response['body'].read())['embedding']\n",
    "    \n",
    "    with open(OUTPUT_FILE_PATH2, 'w', encoding='utf-8') as output_file:\n",
    "        json.dump(data_list, output_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "summary_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edc234-6e09-48df-9a21-491683c00666",
   "metadata": {},
   "source": [
    "In the `chinook_detailed_schema_temp.json` file, the `table_summary` and its corresponding embedding have been added to the schema document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ea3a0-7f48-441c-9d73-faa6f3fd472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_detailed_schema_descriptions(os_client):\n",
    "\n",
    "    with open(OUTPUT_FILE_PATH2, 'r') as file:\n",
    "        schema_data = json.load(file)\n",
    "\n",
    "    bulk_data = []\n",
    "    for table in schema_data:\n",
    "        for table_name, table_info in table.items():\n",
    "            table_doc = {\n",
    "                \"table_name\": table_name,\n",
    "                \"table_desc\": table_info[\"table_desc\"],\n",
    "                \"columns\": [{\"col_name\": col[\"col\"], \"col_desc\": col[\"col_desc\"]} for col in table_info[\"cols\"]],\n",
    "                \"table_summary\": table_info[\"table_summary\"],\n",
    "                \"table_summary_v\": table_info[\"table_summary_v\"]\n",
    "            }\n",
    "            bulk_data.append({\"index\": {\"_index\": INDEX_NAME}})\n",
    "            bulk_data.append(table_doc)\n",
    "    \n",
    "    bulk_data_str = '\\n'.join(json.dumps(item) for item in bulk_data) + '\\n'\n",
    "\n",
    "    response = os_client.bulk(body=bulk_data_str)\n",
    "    if response[\"errors\"]:\n",
    "        print(\"There were errors during bulk indexing:\")\n",
    "        for item in response[\"items\"]:\n",
    "            if 'index' in item and item['index']['status'] >= 400:\n",
    "                print(f\"Error: {item['index']['error']['reason']}\")\n",
    "    else:\n",
    "        print(\"Bulk-inserted all items successfully.\")\n",
    "\n",
    "load_detailed_schema_descriptions(os_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bae4d-72fb-4086-a708-1195335c8fd2",
   "metadata": {},
   "source": [
    "#### Now, the schema description has been stored into OpenSearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
